{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character_Recognition_for_Students.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLnvaR00hLNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thur Nov 7 14:20:37 2019\n",
        "Reference from https://github.com/anujshah1003/own_data_cnn_implementation_keras/blob/master/updated_custom_data_cnn.py\n",
        "@author: RaneChinmayAppa\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import os,cv2\n",
        "\n",
        "import glob\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
        "\n",
        "\n",
        "def sorted_aphanumeric(data):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "    return sorted(data, key=alphanum_key)\n",
        "\n",
        "def gen_image(arr):\n",
        "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
        "    plt.imshow(two_d, interpolation='nearest')\n",
        "    return plt\n",
        "  \n",
        "def unique(list1): \n",
        "      \n",
        "    # insert the list to the set \n",
        "    list_set = set(list1) \n",
        "    # convert the set to the list \n",
        "    unique_list = (list(list_set)) \n",
        "    for x in unique_list: \n",
        "        print(x)\n",
        "        \n",
        "#from sklearn.cross_validation import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PATH = os.getcwd()\n",
        "# Define data path\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/Character Images'   # inset your path\n",
        "\n",
        "data_dir_list = sorted_aphanumeric(os.listdir(data_path)) # os.listdir(data_path)\n",
        "\n",
        "\n",
        "img_rows=128\n",
        "img_cols=128\n",
        "num_channel=1\n",
        "num_epoch=20\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = 34\n",
        "\n",
        "labels_name={'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'A':10,'B':11,'C':12,'D':13,'E':14,'F':15,'G':16,'H':17,'I':18,'J':19,'K':20,'L':21,'M':22,'N':23,'P':24,'R':25,'S':26,'T':27,'U':28,'V':29,'W':30,'X':31,'Y':32,'Z':33} # O,Q is not there in the list\n",
        "\n",
        "img_data_list=[]\n",
        "labels_list = []\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "    img_list = glob.glob(data_path+'/'+ dataset +'/*.png')\n",
        "    \n",
        "    label = labels_name[dataset] # label is generated as the library updated above\n",
        "    for img in img_list:\n",
        "        input_img=cv2.imread(img,1 )\n",
        "        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "        input_img_resize=cv2.resize(input_img,(28,28))\n",
        "        img_data_list.append(input_img_resize)\n",
        "        labels_list.append(label)\n",
        "\n",
        "#print(unique(labels_list))\n",
        "img_data = np.array(img_data_list)\n",
        "img_data = img_data.astype('float32')\n",
        "\n",
        "labels = np.array(labels_list)\n",
        "\n",
        "#print(unique(labels))\n",
        "print(np.unique(labels,return_counts=True))\n",
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "\n",
        "\n",
        "#Shuffle the dataset\n",
        "x,y = shuffle(img_data,Y, random_state=2)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2) # divide data into train and test\n",
        "\n",
        "#Normalization of the data\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "Nv = X_train.shape[0]\n",
        "Nv_test = X_test.shape[0]\n",
        "\n",
        "#reshape data to fit model\n",
        "X_train = X_train.reshape(int(Nv),28,28,1)\n",
        "X_test = X_test.reshape(int(Nv_test),28,28,1)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "##################   add model layers described in the assignment   #######################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "# 8. Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "# 9. Fit model on training data\n",
        "model.fit(X_train, y_train, \n",
        "          batch_size=32, nb_epoch=10, verbose=1) #epochs  = iterations(Nit)\n",
        "\n",
        "# 10. Evaluate model on test data\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "print('Testing accuracy - > ',score[1] * 100)\n",
        " \n",
        "ytested = model.predict_classes(X_test)\n",
        "for i in range(10):\n",
        "  print(\"The Predicted Testing image is =%s verify below\" % ((list(labels_name.keys())[list(labels_name.values()).index(ytested[i])])))\n",
        "  gen_image(X_test[i]).show() # printing image vs the predicted image below\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}